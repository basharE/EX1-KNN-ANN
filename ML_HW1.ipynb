{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from statistics import median\n",
    "from pandas import read_csv\n",
    "from PIL import Image, ImageDraw\n",
    "from statistics import mean\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clause 1 - KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(point1, point2):\n",
    "    point1_ = np.array(point1)\n",
    "    point2_ = np.array(point2)\n",
    "\n",
    "    # calculating Euclidean distance\n",
    "    # using linalg.norm()\n",
    "    dist = np.linalg.norm(point1_ - point2_)\n",
    "\n",
    "    # return Euclidean distance\n",
    "    return dist\n",
    "\n",
    "\n",
    "def knn_sort_func(list_):\n",
    "    return list_['distance']\n",
    "\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, k):\n",
    "        self.internal_list = []\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, train_data):\n",
    "        self.internal_list = train_data\n",
    "\n",
    "    def k_neighbors(self, new_points):\n",
    "        neighbors_list = []\n",
    "        for point in new_points:\n",
    "            neighbors_list.append(self.point_k_neighbors(point[4:132], point[0:4]))\n",
    "        return neighbors_list\n",
    "\n",
    "    def point_k_neighbors(self, new_point_f, new_point_n):\n",
    "        point_k_neighbors_list = []\n",
    "        for point in self.internal_list:\n",
    "            point_name = point.get('point_name')\n",
    "            point_features = point.get('point_data')\n",
    "\n",
    "            dis = euclidean_distance(point_features, new_point_f)\n",
    "            point_name_dis = {'point_name': new_point_n, 'NN_name': point_name, 'distance': dis}\n",
    "            point_k_neighbors_list.append(point_name_dis)\n",
    "        point_k_neighbors_list.sort(key=knn_sort_func)\n",
    "        return point_k_neighbors_list[:self.k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clause 2 - ANN _ KD Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_median(data, dim):\n",
    "    data_dim = []\n",
    "    for point in data:\n",
    "        data_dim.append(point.get(\"point_data\")[dim])\n",
    "    return median(data_dim)\n",
    "\n",
    "\n",
    "def get_dim_larger_data(data, dim, med):\n",
    "    right_data = []\n",
    "    for point in data:\n",
    "        if point.get(\"point_data\")[dim] >= med:\n",
    "            right_data.append(point)\n",
    "    return right_data\n",
    "\n",
    "\n",
    "def get_dim_smaller_data(data, dim, med):\n",
    "    right_data = []\n",
    "    for point in data:\n",
    "        if point.get(\"point_data\")[dim] < med:\n",
    "            right_data.append(point)\n",
    "    return right_data\n",
    "\n",
    "\n",
    "def get_neighbors(current, point):\n",
    "    if len(point) == current.point_dim:\n",
    "        if len(current.data) > current.leave_size:\n",
    "            if point[current.current_dim % current.point_dim] >= current.current_median:\n",
    "                return get_neighbors(current.right, point)\n",
    "            else:\n",
    "                return get_neighbors(current.left, point)\n",
    "        else:\n",
    "            return current.data\n",
    "    else:\n",
    "        return\n",
    "\n",
    "\n",
    "class OurKdTree:\n",
    "    def __init__(self, data, leave_size, point_dim, current_dim):\n",
    "        self.current_median = 0\n",
    "        self.current_dim = current_dim\n",
    "        self.point_dim = point_dim\n",
    "        self.leave_size = leave_size\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.data = data\n",
    "\n",
    "    def build_tree(self):\n",
    "        dim_ = self.current_dim % self.point_dim\n",
    "        if len(self.data) > self.leave_size:\n",
    "            median_ = get_median(self.data, dim_)\n",
    "            self.current_median = median_\n",
    "            right_data = get_dim_larger_data(self.data, dim_, median_)\n",
    "            self.right = OurKdTree(right_data, self.leave_size, self.point_dim, self.current_dim + 1)\n",
    "\n",
    "            left_data = get_dim_smaller_data(self.data, dim_, median_)\n",
    "            self.left = OurKdTree(left_data, self.leave_size, self.point_dim, self.current_dim + 1)\n",
    "\n",
    "            if self.leave_size <= len(right_data):\n",
    "                self.right.build_tree()\n",
    "            if self.leave_size <= len(left_data):\n",
    "                self.left.build_tree()\n",
    "        else:\n",
    "            return self\n",
    "\n",
    "\n",
    "def get_data(file):\n",
    "    f_points = []\n",
    "    data_from_file = read_csv(file)\n",
    "    points_from_file = data_from_file.values.tolist()\n",
    "    for point in points_from_file:\n",
    "        f_points.append({'point_name': point[:4], 'point_data': point[4:]})\n",
    "    return f_points\n",
    "\n",
    "\n",
    "def get_point_dim(data):\n",
    "    if len(data) != 0:\n",
    "        return len(data[0].get('point_data'))\n",
    "    return 0\n",
    "\n",
    "\n",
    "def my_sort_func(e):\n",
    "    return e['distance']\n",
    "\n",
    "\n",
    "def remove_dublicates(list_to):\n",
    "    for i in range(len(list_to) - 1, 0, -1):\n",
    "        if list_to[i] == list_to[i - 1]:\n",
    "            del list_to[i]\n",
    "\n",
    "    return list_to\n",
    "\n",
    "\n",
    "def flat_candidates_list(candidates):\n",
    "    flat_list = []\n",
    "    for candidate in candidates:\n",
    "        for item in candidate:\n",
    "            flat_list.append(item)\n",
    "    return flat_list\n",
    "\n",
    "\n",
    "def get_final_k_neighbors(candidates, point, k):\n",
    "    out = flat_candidates_list(candidates)\n",
    "    res = []\n",
    "    for candidate in out:\n",
    "        res.append({'candidate_point': candidate.get('point_name'),\n",
    "                    'distance': euclidean_distance(candidate.get('point_data'), point)})\n",
    "    res.sort(key=my_sort_func)\n",
    "    sorted_list = remove_dublicates(res)\n",
    "    return sorted_list[0:k]\n",
    "\n",
    "\n",
    "class ANN:\n",
    "    def __init__(self, N, L, k):\n",
    "        self.N = N\n",
    "        self.L = L\n",
    "        self.k = k\n",
    "        self.forest = []\n",
    "        self.data = None\n",
    "\n",
    "    def fit(self, train_data):\n",
    "        self.data = train_data\n",
    "        for tree in range(self.L):\n",
    "            self.forest.append(OurKdTree(self.data, self.N, get_point_dim(self.data), tree))\n",
    "        for tree in self.forest:\n",
    "            tree.build_tree()\n",
    "\n",
    "    def k_neighbors(self, new_points):\n",
    "        neighbors_list = []\n",
    "        for point in new_points:\n",
    "            neighbors_list.append({'the_point': point[:4], 'k_neighbors': self.point_k_neighbors(point[4:])})\n",
    "        return neighbors_list\n",
    "\n",
    "    def point_k_neighbors(self, new_point):\n",
    "        candidates = []\n",
    "        for tree in self.forest:\n",
    "            candidates.append(get_neighbors(tree, new_point))\n",
    "        return get_final_k_neighbors(candidates, new_point, self.k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clause 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio_sort_func(e):\n",
    "    return e['ratio']\n",
    "\n",
    "\n",
    "def ratio_method(data):\n",
    "    relevant_points = []\n",
    "    for point in data:\n",
    "        ratio = point.get('k_neighbors')[0].get('distance') / point.get('k_neighbors')[1].get('distance')\n",
    "        if ratio < 0.8:\n",
    "            relevant_points.append({'the_point': point, 'ratio': ratio})\n",
    "    relevant_points.sort(key=ratio_sort_func)\n",
    "    return relevant_points\n",
    "    # From 913 point in \"Hananya2\" data, only 68 point have a nearest neighbor\n",
    "    # in accordance with \"Ratio Test\".\n",
    "    # This method creates a new list that contains only these point\n",
    "    # It prints the relevant point list, and the length of it (amout of points)\n",
    "\n",
    "\n",
    "def show_10_points(img1, img2, data):\n",
    "    im_1 = Image.open(img1)\n",
    "    im_2 = Image.open(img2)\n",
    "    for point in data:\n",
    "        color = '#%06X' % randint(0, 0xFFFFFF)\n",
    "        draw2 = ImageDraw.Draw(im_2)\n",
    "        x_point2 = point.get('the_point').get('the_point')[1]\n",
    "        y_point2 = point.get('the_point').get('the_point')[0]\n",
    "        draw2.ellipse(((x_point2, y_point2), (x_point2 + 8, y_point2 + 8)), fill=color, outline=color)\n",
    "        draw1 = ImageDraw.Draw(im_1)\n",
    "        x_point1 = point.get('the_point').get('the_point')[1]\n",
    "        y_point1 = point.get('the_point').get('the_point')[0]\n",
    "        draw1.ellipse(((x_point1, y_point1), (x_point1 + 8, y_point1 + 8)), fill=color, outline=color)\n",
    "    im_2.show()\n",
    "    im_1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clause 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ann_result(result, ann_results):\n",
    "    for ann_result in ann_results:\n",
    "        if ann_result.get('the_point') == result:\n",
    "            return ann_result.get('k_neighbors')[0].get('distance')\n",
    "    return 0\n",
    "\n",
    "\n",
    "def calculate_error_rate(knn_results, ann_results):\n",
    "    rate_sum = 0\n",
    "    for result in knn_results:\n",
    "        rate_sum = (get_ann_result(result[0].get('point_name'), ann_results) / result[0].get('distance')) + rate_sum\n",
    "    return ((1 / len(knn_results)) * rate_sum) - 1\n",
    "\n",
    "\n",
    "def calculate_accuracy(N, L, train, test):\n",
    "    knn_obj = KNN(1)\n",
    "\n",
    "    knn_obj.fit(train)\n",
    "    knn_results = knn_obj.k_neighbors(test)\n",
    "\n",
    "    ann_obj = ANN(N, L, 1)\n",
    "    ann_obj.fit(train)\n",
    "    ann_results = ann_obj.k_neighbors(test)\n",
    "\n",
    "    error = calculate_error_rate(knn_results, ann_results)\n",
    "    return error\n",
    "\n",
    "\n",
    "def cross_validation(N, L, k, train):\n",
    "    bulk_size = round(len(train) / k)\n",
    "    bulk_error_rate = []\n",
    "    for i in range(0, k):\n",
    "        bulk_train = train[0: (bulk_size * i)] + train[(bulk_size * i) + bulk_size:]\n",
    "        bulk_test_dic = train[0 + (bulk_size * i):(bulk_size * i) + bulk_size]\n",
    "        bulk_test = []\n",
    "        for value in bulk_test_dic:\n",
    "            temp = value.get('point_name') + value.get('point_data')\n",
    "            bulk_test.append(temp)\n",
    "        bulk_error_rate.append(calculate_accuracy(N, L, bulk_train, bulk_test))\n",
    "    return mean(bulk_error_rate)\n",
    "\n",
    "\n",
    "def grid_search(k, train):\n",
    "    n_random_list = []\n",
    "    l_random_list = []\n",
    "    # Generate random parameters for L,N\n",
    "    for i in range(0, 10):\n",
    "        n = random.randint(2, 30)\n",
    "        n_random_list.append(n)\n",
    "        n = random.randint(2, 30)\n",
    "        l_random_list.append(n)\n",
    "    print('N 10 values (randomly chosen): ', n_random_list)\n",
    "    print('L 10 values (randomly chosen): ', l_random_list)\n",
    "\n",
    "    # Find the lowest error rate using cross_validation() method\n",
    "    lowest_error = {'error_rate': 1, 'N_value': 0, 'L_value': 0}\n",
    "    for n in n_random_list:\n",
    "        for l in l_random_list:\n",
    "            value = cross_validation(n, l, k, train)\n",
    "            if value < lowest_error.get('error_rate'):\n",
    "                lowest_error = {'error_rate': value, 'N_value': n, 'L_value': l}\n",
    "    print('Optimal combination is : ', lowest_error)\n",
    "    return lowest_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clause 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# method to calculate the error of given test data and training data\n",
    "def error(train_file,test_file,N,L):\n",
    "    \n",
    "    # run same training data and test data on both KNN, ANN\n",
    "    knn = KNN(5)\n",
    "    knn.fit(train_file)\n",
    "    \n",
    "    ann = ANN(N, L, 5)\n",
    "    ann.fit(train_file)\n",
    "    test_data = read_csv(test_file)\n",
    "    test_list = test_data.iloc[0:1, 0:132]\n",
    "    test_points = test_list.values.tolist()\n",
    "    \n",
    "    knn_res = knn.k_neighbors(test_points)\n",
    "    ann_res = ann.k_neighbors_(test_points)\n",
    "    \n",
    "    # calculate sum of distances from KNN\n",
    "    sum_knn_res = 0\n",
    "    for list_knn in knn_res:\n",
    "        for dis_knn in list_knn:\n",
    "            sum_knn_res += dis_knn\n",
    "    \n",
    "    # calculate sum of distances from ANN\n",
    "    sum_ann_res = 0\n",
    "    for list_ann in ann_res:\n",
    "        for dis_ann in list_ann:\n",
    "            sum_ann_res += dis_ann\n",
    "            \n",
    "    # calculate the error   \n",
    "    return (sum_ann_res/sum_knn_res)-1\n",
    "\n",
    "# method to calculate the speed of ANN with given files, params\n",
    "def calc_speed_ann(train_file,test_file,N,L,K):\n",
    "    t0 = time.process_time()\n",
    "    ann = ANN(N, L, K)\n",
    "    ann.fit(train_file)\n",
    "    test_data = read_csv(test_file)\n",
    "    test_list = test_data.iloc[0:1, 0:132]\n",
    "    test_points = test_list.values.tolist()\n",
    "    ann.k_neighbors_(test_points)\n",
    "    t1 = time.process_time()\n",
    "    return t1-t0\n",
    "\n",
    "def my_func_(list_):\n",
    "    return list_['speed']\n",
    "\n",
    "\n",
    "# clause 5 method : returns 5 pairs (L,N) of ANN params that ANN runs fastest, with error =< error given\n",
    "def five_fastest_param (train_file,test_file):\n",
    "    fastest_params_andspeed = [] # like {params: [L,N], speed: s}\n",
    "    for i in range (100):\n",
    "        N = random.randint(1,10)\n",
    "        L = random.randint(1,10)\n",
    "        \n",
    "        # check error condition:\n",
    "        if error(train_file,test_file,N,L) < 0.1:\n",
    "             #  run ANN with L,N (k=3), save params and speed\n",
    "             params_andspeed = {'params': [N,L], 'speed': calc_speed_ann(train_file,test_file,N,L,3)}\n",
    "             fastest_params_andspeed.append(params_andspeed)\n",
    "\n",
    "    # sort by speed\n",
    "    fastest_params_andspeed.sort(key=my_func_)\n",
    "    # return 5 fastest\n",
    "    return fastest_params_andspeed[0:5]\n",
    "\n",
    "# clause 5 - final (+ plt)\n",
    "def five_fastest_and_plt (train_file,test_file):\n",
    "    \n",
    "    # print five fastest params for given data\n",
    "    fastest = five_fastest_param (train_file,test_file)\n",
    "    \n",
    "    # graph plotting\n",
    "    params = [] # X = labels\n",
    "    times = [] # Y = times\n",
    "    for i in fastest:\n",
    "        params.append(i['params'])\n",
    "        times.append(i['speed'])\n",
    "        \n",
    "    y_pos = np.arange(len(params))\n",
    "    plt.bar(y_pos, times, align='center',alpha=0.5)\n",
    "    plt.xticks(y_pos,params)\n",
    "    plt.ylabel('Time')\n",
    "    plt.xlabel('Params')\n",
    "    plt.title('5 fastest params in ANN, and time taken')\n",
    "    plt.show\n",
    "    \n",
    "    print(fastest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clause 6 (fastest params: N=L=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def fastest_params_plt(train_file,test_file):\n",
    "    \n",
    "    errors = []\n",
    "    times = []\n",
    "    \n",
    "    for i in range (10):\n",
    "        p = ANN(1, 1, 5)\n",
    "        p.fit(train_file)\n",
    "        data1 = read_csv(test_file)\n",
    "        the_list1 = data1.iloc[0:1, 0:132]\n",
    "        points = the_list1.values.tolist()\n",
    "        r = p.k_neighbors(points)\n",
    "        print (\"Iteration: \" + str(i+1))\n",
    "        print(*r, sep=\"\\n\")\n",
    "        print (\"Error: \" + str(error(train_file,test_file,1,1)))\n",
    "        print (\"Time: \" + str(calc_speed_ann(train_file,test_file,1,1,3))+\"\\n\")\n",
    "        \n",
    "        errors.append(error(train_file,test_file,1,1))\n",
    "        times.append(calc_speed_ann(train_file,test_file,1,1,5))\n",
    "    \n",
    "    plt.plot(errors,times)\n",
    "    plt.ylabel('Time')\n",
    "    plt.xlabel('Error')\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clause 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N 10 values (randomly chosen):  [10, 28, 19, 7, 22, 16, 2, 3, 29, 16]\n",
      "L 10 values (randomly chosen):  [14, 3, 13, 16, 30, 16, 5, 15, 19, 26]\n",
      "Optimal combination is :  {'error_rate': 0.006106612987755056, 'N_value': 29, 'L_value': 30}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'error_rate': 0.006106612987755056, 'N_value': 29, 'L_value': 30}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_ = get_data(\"Hananya1.csv\")\n",
    "nn_data = read_csv(\"Hananya2.csv\")\n",
    "data_list = nn_data.iloc[0:, 0:132]\n",
    "points_to_test = data_list.values.tolist()\n",
    "\n",
    "'''\n",
    "The constructor ANN accepts 3 arguments\n",
    "1-  N: the maximum number of points existed in each leaf in the tree\n",
    "2-  L: the number of trees created in our forest\n",
    "3-  k: number of neighbors we need to get for every point \n",
    "'''\n",
    "# Clause 3 - main\n",
    "p = ANN(10, 20, 2)\n",
    "p.fit(train_data_)\n",
    "r = p.k_neighbors(points_to_test)\n",
    "best_points = ratio_method(r)\n",
    "show_10_points(\"Hananya1.JPG\", \"Hananya2.JPG\", best_points[:10])\n",
    "\n",
    "# Clause 4 - main\n",
    "grid_search(4, train_data_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
